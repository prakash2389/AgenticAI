# -*- coding: utf-8 -*-
"""langgraph_openai_example.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QOyd_ChWhqBlQMUPUnn-savKEnDOQ8nq
"""

!pip install --upgrade langchain langchain-community langgraph

!pip install langchain-ollama

!pip install langchain-openai

from typing import List, Dict

from langgraph.graph import StateGraph, START, END

from langchain_openai.chat_models import ChatOpenAI
# from langchain_ollama.llms import OllamaLLM

#Define STate
class State(Dict):
  messages : List[Dict[str, str]]

llm= ChatOpenAI(api_key = "********************"
)

llm.invoke("Asda")

# Step 2: Initialize StateGraph
graph_builder = StateGraph(State)

# Define chatbot function
def chatbot(state: State):
    response = llm.invoke(state["messages"])
    state["messages"].append({"role": "assistant", "content": response})  # Treat response as a string
    return {"messages": state["messages"]}

# Add nodes and edges
graph_builder.add_node("chatbot", chatbot)

# Add nodes and edges
graph_builder.add_edge(START, "chatbot")

# Add nodes and edges
graph_builder.add_edge("chatbot", END)

graph = graph_builder.compile()

# Stream updates

def stream_graph_updates(user_input: str):
    state = {"messages": [{"role": "user", "content": user_input}]}
    for event in graph.stream(state):
        for value in event.values():
            print("Assistant:", value["messages"][-1]["content"])

# Run chatbot in a loop
while True:
    try:
        user_input = input("User: ")
        if user_input.lower() in ["quit", "exit", "q"]:
            print("Goodbye!")
            break

        stream_graph_updates(user_input)
    except Exception as e:
        print(f"An error occurred: {e}")
        break

